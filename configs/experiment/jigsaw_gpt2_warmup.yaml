# @package _global_

defaults:
  - override /module: classification_warmup.yaml

module:
    model:
        _target_: transformers.GPT2ForSequenceClassification.from_pretrained
        num_labels: 1
        pretrained_model_name_or_path: gpt2

        
collate_fn:
    padding: False
        
datamodule:
    batch_size: 32
    train_data_path: ${jigsaw}/train_subset.csv
    test_data_path: ${jigsaw}/test_private_expanded.csv
    tokenizer:
        #_target_: transformers.GPT2Tokenizer
        pad_token: "[PAD]"
    
trainer:
    accelerator: gpu
    devices: 1
    
    

